---
title: "NOAA Analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Synopsis
The National Oceanic and Atmospheric Administration (NOAA) has been tasked with tracking and recording extreme weather events as well as their damage. They publish monthly updates to *Storm Data*, which makes note of significant weather events at the county level in the United States. This data is freely available to the public and is therefore used for a variety of various research and analysis projects. 

This document makes use of *Storm Data* reports from 1950 - 2011 to answer some basic questions about the effect of weather events on both human population health as well as the economy.

### Data Processing

#### Loading the raw dataset
The original zip file was downloaded from the course website and the two date columns, `BGN_DATE` and `END_DATE` were forced from character strings into a proper date format.
```{r load_packages, cache = TRUE}
library(tidyverse)
library(lubridate)

download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2",
              "stormdata.csv.bz2")
data <- read_csv("stormdata.csv.bz2", locale=locale(tz="UTC"))
data$BGN_DATE <- parse_date_time(data$BGN_DATE, "mdyHMS")
data$END_DATE <- parse_date_time(data$END_DATE, "mdyHMS")
```

#### Exploratory analysis
Once the data were loaded in, a brief exploration was performed to get a better understanding of the types of events and their frequency, as well as a check for missing data.
```{r}
group_by(data, EVTYPE) %>%
    summarize(Total = n()) %>%
    filter(Total > 10000)

```


### Results
discussion and plots here...





